{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#記得備註此處之資料夾'IRTM'在上傳時皆改為'data'\n",
    "import sys\n",
    "import nltk\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "word_list = ['is', 'am', 'are', 'was', 'were']\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords from txt\n",
    "my_file = open(\"stopwords.txt\", \"r\")\n",
    "stopwords = my_file.read()\n",
    "stopwords = [stopwords.translate({ ord(c): None for c in '\" ' }).split(\",\") ][0]#delete punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    data = [i.strip() for i in data.split(' ')]\n",
    "    text = [i.lower() for i in data]\n",
    "    text = [i.translate({ ord(c): None for c in '\"1234567890' }) for i in text] #delete punctuation\n",
    "    text = [i.translate({ ord(c): None for c in \"#$%&'()*+,-./:;!<=>?@[\\]^_`{|~} \" }) for i in text] #delete punctuation\n",
    "    text = [ps.stem(i) for i in text] #porter's algo\n",
    "    text = ['be' if idx in word_list else idx for idx in text] #lemmatization\n",
    "    text = [i for i in text if i not in stopwords] #stopwords delete\n",
    "    text = list(filter(None, text)) #去除空字元\n",
    "    return text\n",
    "\n",
    "def buildDict(text): #算字出現數，一篇多次只算1\n",
    "    text = np.unique(text).tolist()\n",
    "    for word in text:\n",
    "        if word in word_dict:\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {}\n",
    "for i in range(1, 1096):\n",
    "    with open(f'./data/{i}.txt') as f:\n",
    "        data=f.read()\n",
    "        text = tokenize(data) \n",
    "        buildDict(text)\n",
    "sorted_dict = dict( sorted(word_dict.items(), key=lambda x: x[0]) ) #照字母排\n",
    "wordSize = len(word_dict) #總term數\n",
    "wordSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [f'{i}' for i in range(1, wordSize+1)] \n",
    "new_d =[{i: j} for i, j in sorted_dict.items()]\n",
    "new_dict = dict(zip(label, new_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aan', {'wid': '1', 'wcount': 1}), ('aaron', {'wid': '2', 'wcount': 2}), ('aback', {'wid': '3', 'wcount': 1}), ('abahd', {'wid': '4', 'wcount': 1}), ('abandon', {'wid': '5', 'wcount': 37}), ('abat', {'wid': '6', 'wcount': 1}), ('abc', {'wid': '7', 'wcount': 49}), ('abccom', {'wid': '8', 'wcount': 1}), ('abcnewscom', {'wid': '9', 'wcount': 3}), ('abdallah', {'wid': '10', 'wcount': 2})]\n"
     ]
    }
   ],
   "source": [
    "ans_dict = {}\n",
    "with open('./dictionary.txt', 'w') as f:\n",
    "    f.write('t_index\\tterm\\tdf\\n')\n",
    "    for key, words in new_dict.items():\n",
    "        for wd in words:\n",
    "            ans_dict[wd] = {'wid':key, 'wcount':words[wd]} \n",
    "            tmp = f'{key}\\t{wd}\\t{words[wd]}\\n'\n",
    "            f.write(tmp)\n",
    "print(list(ans_dict.items())[:10]) #長這樣照字母排"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 build each doc tf-idf\n",
    "vectorSpace = [[]] #使append從1開始\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "for i in range(1, 1096):#1096\n",
    "    tmp_V = np.zeros(wordSize+1)\n",
    "    with open(f'./data/{i}.txt') as f:\n",
    "        data = f.read()\n",
    "        text = tokenize(data)\n",
    "        text.sort()\n",
    "        df = pd.value_counts(text)        \n",
    "        #display(df)\n",
    "        \n",
    "        with open(f'./output/doc{i}.txt', 'w') as wf:\n",
    "            wf.write(f'{len(np.unique(text))}\\n')\n",
    "            wf.write('t_index\\ttf-idf\\n')             \n",
    "            for k in np.unique(text):               \n",
    "                wid    = ans_dict[k]['wid']\n",
    "                wcount = ans_dict[k]['wcount']\n",
    "                #print(k, df[k], wid, wcount) #字，出現在此d幾次，字的id，幾個d有此字\n",
    "                tf = df[k]\n",
    "                idf = math.log(1095/wcount, 10) #底數10\n",
    "                tmp_V[int(wid)] = tf*idf #存進向量vector\n",
    "                wf.write(f'{wid}\\t{tf*idf}\\n')\n",
    "            #display(tmp_V)\n",
    "            vectorSpace.append(tmp_V)\n",
    "#vectorSpace[2][7]#第二篇doc內確實有編號7的term        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3 compute cosine similarity\n",
    "from numpy.linalg import norm\n",
    "def cosine(Docx, Docy):\n",
    "    return np.dot(Docx, Docy)/(norm(Docx)*norm(Docy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2057485539860974\n"
     ]
    }
   ],
   "source": [
    "print(cosine(vectorSpace[1], vectorSpace[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
